{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "plastic-kingdom",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-05-19T21:54:00.025873Z",
     "iopub.status.busy": "2021-05-19T21:54:00.025446Z",
     "iopub.status.idle": "2021-05-19T21:54:00.032866Z",
     "shell.execute_reply": "2021-05-19T21:54:00.031181Z",
     "shell.execute_reply.started": "2021-05-19T21:54:00.025833Z"
    },
    "papermill": {
     "duration": 0.011033,
     "end_time": "2021-05-23T19:31:59.295205",
     "exception": false,
     "start_time": "2021-05-23T19:31:59.284172",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "precise-valuation",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T19:31:59.332468Z",
     "iopub.status.busy": "2021-05-23T19:31:59.331919Z",
     "iopub.status.idle": "2021-05-23T19:32:53.139659Z",
     "shell.execute_reply": "2021-05-23T19:32:53.138727Z",
     "shell.execute_reply.started": "2021-05-23T18:55:21.278459Z"
    },
    "papermill": {
     "duration": 53.834373,
     "end_time": "2021-05-23T19:32:53.139818",
     "exception": false,
     "start_time": "2021-05-23T19:31:59.305445",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/d/alvaromunoz/textstat/Pyphen-0.10.0-py3-none-any.whl\r\n",
      "Installing collected packages: Pyphen\r\n",
      "Successfully installed Pyphen-0.10.0\r\n",
      "Processing /kaggle/input/d/alvaromunoz/textstat/textstat-0.7.0-py3-none-any.whl\r\n",
      "Requirement already satisfied: pyphen in /opt/conda/lib/python3.7/site-packages (from textstat==0.7.0) (0.10.0)\r\n",
      "Installing collected packages: textstat\r\n",
      "Successfully installed textstat-0.7.0\r\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "!pip install ../input/d/alvaromunoz/textstat/Pyphen-0.10.0-py3-none-any.whl\n",
    "!pip install ../input/d/alvaromunoz/textstat/textstat-0.7.0-py3-none-any.whl\n",
    "import torch\n",
    "from torch import optim, nn\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import psutil\n",
    "\n",
    "import warnings\n",
    "import string\n",
    "import re\n",
    "import math\n",
    "from collections import Counter\n",
    "import pkg_resources\n",
    "from functools import lru_cache\n",
    "\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import os\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "import textstat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "whole-activity",
   "metadata": {
    "papermill": {
     "duration": 0.012226,
     "end_time": "2021-05-23T19:32:53.164934",
     "exception": false,
     "start_time": "2021-05-23T19:32:53.152708",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "minimal-documentary",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T19:32:53.196757Z",
     "iopub.status.busy": "2021-05-23T19:32:53.195403Z",
     "iopub.status.idle": "2021-05-23T19:32:53.198291Z",
     "shell.execute_reply": "2021-05-23T19:32:53.197800Z",
     "shell.execute_reply.started": "2021-05-23T18:56:15.273656Z"
    },
    "papermill": {
     "duration": 0.021211,
     "end_time": "2021-05-23T19:32:53.198429",
     "exception": false,
     "start_time": "2021-05-23T19:32:53.177218",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    # Debugging\n",
    "    DEBUG_MODE = False\n",
    "    SEED = 0\n",
    "\n",
    "    # Navigation\n",
    "#     ROOT_PATH = get_project_root()\n",
    "    RAW_DATA_PATH = Path('/kaggle/input/commonlitreadabilityprize')\n",
    "    MODEL_SAVE_PATH = Path('/kaggle/working/models')\n",
    "    MODEL_SAVE_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Dataset Parameters\n",
    "    PREPROCESS_TEXT = False\n",
    "    MAX_LEN = 512\n",
    "    FOLDS = 5\n",
    "    EMBED = False  # Don't convert to word embeddings (use if embedding will be done simultaneously with modelling)\n",
    "    READABILITY_METRICS = True  # Include readability metrics in dataset\n",
    "\n",
    "    # Training Parameters\n",
    "    EPOCHS = 3\n",
    "    BATCH_SIZE = 64\n",
    "    WEIGHT_LOSS = True  # If true, loss function is weighted based on the standard error of readability scores\n",
    "    SKIP_TRAINING = False\n",
    "\n",
    "    # Model Parameters\n",
    "    DROPOUT = 0.3\n",
    "    EMBEDDINGS_ONLY = False  # Only returns the embeddings, no final estimate.\n",
    "    # These can be used for clustering or for transfer learning using non-Deep Learning methods.\n",
    "\n",
    "    LAYER_UNITS = (768 + 13, 128, 64, 1)  # Number of units in each layer of fully connected network\n",
    "    # 768 + 13 = BERT embedding dim + readability_score dim\n",
    "\n",
    "    # Optimizer Parameters\n",
    "    optimizer_params = {\n",
    "        'lr': 1e-4\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civilian-couple",
   "metadata": {
    "papermill": {
     "duration": 0.01207,
     "end_time": "2021-05-23T19:32:53.222735",
     "exception": false,
     "start_time": "2021-05-23T19:32:53.210665",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "broadband-compact",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T19:32:53.253162Z",
     "iopub.status.busy": "2021-05-23T19:32:53.252630Z",
     "iopub.status.idle": "2021-05-23T19:32:53.256266Z",
     "shell.execute_reply": "2021-05-23T19:32:53.256705Z",
     "shell.execute_reply.started": "2021-05-23T18:56:15.285046Z"
    },
    "papermill": {
     "duration": 0.022353,
     "end_time": "2021-05-23T19:32:53.256836",
     "exception": false,
     "start_time": "2021-05-23T19:32:53.234483",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_text_features(excerpt, as_dict=True):\n",
    "    num_words = len(excerpt.split(' '))\n",
    "    features = {}\n",
    "    features['flesch_reading_ease'] = textstat.flesch_reading_ease(excerpt)\n",
    "    features['smog_index'] = textstat.smog_index(excerpt)\n",
    "    features['flesch_kincaid_grade'] = textstat.flesch_kincaid_grade(excerpt)\n",
    "    features['coleman_liau_index'] = textstat.coleman_liau_index(excerpt)\n",
    "    features['automated_readability_index'] = textstat.automated_readability_index(excerpt)\n",
    "    features['dale_chall_readability_score'] = textstat.dale_chall_readability_score(excerpt)\n",
    "    features['difficult_words'] = textstat.difficult_words(excerpt) / num_words\n",
    "    features['linsear_write_formula'] = textstat.linsear_write_formula(excerpt)\n",
    "    features['gunning_fog'] = textstat.gunning_fog(excerpt)\n",
    "    features['fernandez_huerta'] = textstat.fernandez_huerta(excerpt)\n",
    "    features['szigriszt_pazos'] = textstat.szigriszt_pazos(excerpt)\n",
    "    features['gutierrez_polini'] = textstat.gutierrez_polini(excerpt)\n",
    "    features['crawford'] = textstat.crawford(excerpt)\n",
    "    if as_dict:\n",
    "        return features\n",
    "    else:\n",
    "        return list(features.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modified-suffering",
   "metadata": {
    "papermill": {
     "duration": 0.011379,
     "end_time": "2021-05-23T19:32:53.279983",
     "exception": false,
     "start_time": "2021-05-23T19:32:53.268604",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "opposed-douglas",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T19:32:53.318635Z",
     "iopub.status.busy": "2021-05-23T19:32:53.317350Z",
     "iopub.status.idle": "2021-05-23T19:32:53.319828Z",
     "shell.execute_reply": "2021-05-23T19:32:53.320299Z",
     "shell.execute_reply.started": "2021-05-23T18:56:15.297251Z"
    },
    "papermill": {
     "duration": 0.02887,
     "end_time": "2021-05-23T19:32:53.320450",
     "exception": false,
     "start_time": "2021-05-23T19:32:53.291580",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_raw_data(config):\n",
    "    \"\"\" Downloads and extracts data from Kaggle and stores in '../raw' ready to be processed.\n",
    "    \"\"\"\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logger.info('Downloading raw data')\n",
    "\n",
    "    output_path = config.RAW_DATA_PATH\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    os.system(f'kaggle competitions download -c commonlitreadabilityprize -p {output_path}')\n",
    "\n",
    "    for f in output_path.iterdir():\n",
    "        if f.suffix == '.zip':\n",
    "            with zipfile.ZipFile((output_path / f), 'r') as zip_ref:\n",
    "                zip_ref.extractall(output_path)\n",
    "\n",
    "\n",
    "class ReadabilityPredictorDataset(Dataset):\n",
    "    def __init__(self, config, train=True):\n",
    "        super().__init__()\n",
    "        get_raw_data(config)\n",
    "\n",
    "        self.config = config\n",
    "        self.train = train\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('../input/bert-base-uncased/vocab.txt', do_lower_case=True)\n",
    "\n",
    "        if self.train:\n",
    "            fn = 'train.csv'\n",
    "        else:\n",
    "            fn = 'test.csv'\n",
    "\n",
    "        train_file_path = (config.RAW_DATA_PATH / fn)\n",
    "        self.train_file = pd.read_csv(train_file_path)\n",
    "\n",
    "        if self.config.DEBUG_MODE:\n",
    "            self.train_file = self.train_file.iloc[:20]\n",
    "        self.text = self.train_file['excerpt'].to_numpy()\n",
    "\n",
    "        if self.train:\n",
    "            self.targets = self.train_file['target'].to_numpy()\n",
    "            self.std_error = self.train_file['standard_error'].to_numpy()\n",
    "        else:\n",
    "            self.ids = self.train_file['id'].to_numpy()\n",
    "\n",
    "        if self.config.PREPROCESS_TEXT:\n",
    "            self.preprocess_text()\n",
    "\n",
    "#         if self.config.EMBED:\n",
    "#             self.bert = BertModel.from_pretrained('../input/roberta-transformers-pytorch/roberta-base/pytorch_model.bin', return_dict=False)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.train_file)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        item_text = self.text[item]\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            item_text,\n",
    "            max_length=self.config.MAX_LEN,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "\n",
    "        if self.train:\n",
    "            data = {'raw': item_text, 'target': self.targets[item], 'weight': 1 / (1 + self.std_error[item])}\n",
    "        else:\n",
    "            data = {'raw': item_text, 'id': self.ids[item]}\n",
    "        if self.config.EMBED:\n",
    "            _, data['embedding'] = self.bert(\n",
    "                data['ids'], attention_mask=data['mask'], token_type_ids=data['token_type_ids']\n",
    "            )\n",
    "        else:\n",
    "            data.update({\n",
    "                'ids': inputs['input_ids'].squeeze(),\n",
    "                'mask': inputs['attention_mask'].squeeze(),\n",
    "                'token_type_ids': inputs['token_type_ids'].squeeze(),\n",
    "            })\n",
    "\n",
    "        if self.config.READABILITY_METRICS:\n",
    "            readability_features = build_text_features(item_text, as_dict=False)\n",
    "            data['readability_metrics'] = torch.tensor(readability_features)\n",
    "\n",
    "        return data\n",
    "\n",
    "    def preprocess_text(self):\n",
    "        \"\"\"\n",
    "        Preprocesses the text for use by the model (may not be necessary but, we'll see with time).\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inappropriate-feelings",
   "metadata": {
    "papermill": {
     "duration": 0.011548,
     "end_time": "2021-05-23T19:32:53.343981",
     "exception": false,
     "start_time": "2021-05-23T19:32:53.332433",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cosmetic-dallas",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T19:32:53.378588Z",
     "iopub.status.busy": "2021-05-23T19:32:53.377387Z",
     "iopub.status.idle": "2021-05-23T19:32:53.380140Z",
     "shell.execute_reply": "2021-05-23T19:32:53.379694Z",
     "shell.execute_reply.started": "2021-05-23T18:56:15.316661Z"
    },
    "papermill": {
     "duration": 0.024859,
     "end_time": "2021-05-23T19:32:53.380250",
     "exception": false,
     "start_time": "2021-05-23T19:32:53.355391",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BERTTextReadabilityPredictorBasic(nn.Module):\n",
    "    def __init__(self, config, device='cpu'):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.bert = BertModel.from_pretrained('../input/bert-base-uncased', return_dict=False)\n",
    "        self.drop = nn.Dropout(config.DROPOUT)\n",
    "        self.fc = SimpleMLP(layer_units=config.LAYER_UNITS, dropout=config.DROPOUT, device=device)\n",
    "        self.fc.to(device)\n",
    "\n",
    "    def forward(self, data):\n",
    "        # print(data['ids'].shape, data['mask'].shape, data['token_type_ids'].shape)\n",
    "        _, out = self.bert(\n",
    "            data['ids'], attention_mask=data['mask'], token_type_ids=data['token_type_ids']\n",
    "        )\n",
    "\n",
    "        if self.config.EMBEDDINGS_ONLY:\n",
    "            return out\n",
    "\n",
    "        if self.config.READABILITY_METRICS:\n",
    "            out = torch.cat((out, data['readability_metrics']), dim=1)\n",
    "        out = self.drop(out)\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self, layer_units=(768, 64, 64, 1), dropout=0.5, device='cpu', **kwargs):\n",
    "        super().__init__()\n",
    "        self.bn_layers = nn.ModuleList([\n",
    "            nn.BatchNorm1d(layer_units[i]).to(device) for i in range(len(layer_units)-1)\n",
    "        ])\n",
    "        self.fc_layers = nn.ModuleList([\n",
    "            nn.Linear(layer_units[i], layer_units[i+1]).to(device) for i in range(len(layer_units)-1)\n",
    "        ])\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "    def forward(self, data):\n",
    "        num_layers = len(self.fc_layers)\n",
    "        out = data\n",
    "        for layer in range(num_layers):\n",
    "            out = self.bn_layers[layer](out)\n",
    "            out = self.fc_layers[layer](out)\n",
    "            if layer != num_layers - 1:\n",
    "                out = self.dropout(out)\n",
    "                out = self.act(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "partial-westminster",
   "metadata": {
    "papermill": {
     "duration": 0.011337,
     "end_time": "2021-05-23T19:32:53.402935",
     "exception": false,
     "start_time": "2021-05-23T19:32:53.391598",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "hazardous-taylor",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T19:32:53.457442Z",
     "iopub.status.busy": "2021-05-23T19:32:53.449564Z",
     "iopub.status.idle": "2021-05-23T19:32:53.459988Z",
     "shell.execute_reply": "2021-05-23T19:32:53.459493Z",
     "shell.execute_reply.started": "2021-05-23T18:56:15.331665Z"
    },
    "papermill": {
     "duration": 0.045613,
     "end_time": "2021-05-23T19:32:53.460089",
     "exception": false,
     "start_time": "2021-05-23T19:32:53.414476",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    os.environ['PYTHONASSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, config, val_fold=1):\n",
    "#         self.h = hpy()\n",
    "        set_seed(config.SEED)\n",
    "        self.config = config\n",
    "        self.val_fold = val_fold\n",
    "        self.model_timestamp = datetime.datetime.now().strftime('%m%d-%H%M%S')\n",
    "        if torch.cuda.is_available():\n",
    "            self.device = torch.device(\"cuda\")\n",
    "        else:\n",
    "            self.device = torch.device(\"cpu\")\n",
    "        print(self.device)\n",
    "        self.dataset = ReadabilityPredictorDataset(config)\n",
    "        self.test_ds = ReadabilityPredictorDataset(config, train=False)\n",
    "        self.train_ds, self.val_ds = None, None\n",
    "        self.train_loader, self.val_loader, self.test_loader = None, None, None\n",
    "        self.make_loaders()\n",
    "        self.best_loss = float(\"inf\")\n",
    "        self.best_model = None\n",
    "\n",
    "        self.model = BERTTextReadabilityPredictorBasic(config, device=self.device)\n",
    "        self.model.to(self.device).float()\n",
    "        if self.config.SKIP_TRAINING:\n",
    "            self.load_checkpoint((config.MODEL_SAVE_PATH / config.SAVED_MODEL))\n",
    "\n",
    "        # Freezes all BERT weights. You'll want to adapt learning to unfreeze these once LR decreases.\n",
    "        for param in self.model.bert.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        param_optimizer = list(self.model.named_parameters())\n",
    "        no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "        optimizer_parameters = [\n",
    "            {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "             'weight_decay': 0.0001},\n",
    "            {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "             'weight_decay': 0.0}\n",
    "        ]\n",
    "        self.optimizer = optim.AdamW(optimizer_parameters, **config.optimizer_params)\n",
    "        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            self.optimizer, mode='min', factor=0.1, patience=0, verbose=True)\n",
    "        self.criterion = loss_fn\n",
    "        self.current_epoch = None\n",
    "\n",
    "        # Tensorboard writer\n",
    "#         datetime_stamp = datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "#         run_name = f\"CommonLit_{datetime_stamp}\"\n",
    "#         self.writer = SummaryWriter(f'runs/{run_name}')\n",
    "\n",
    "        self.model_name = None\n",
    "        self.predictions = None\n",
    "\n",
    "    def run(self):\n",
    "        if not self.config.SKIP_TRAINING:\n",
    "            epoch_pbar = tqdm.tqdm(range(1, self.config.EPOCHS + 1), desc='Running training...')\n",
    "            for epoch in epoch_pbar:\n",
    "                try:\n",
    "                    self.current_epoch = epoch\n",
    "                    self.phase(train=True)\n",
    "                    if self.val_fold:\n",
    "                        self.phase(train=False)\n",
    "                except:\n",
    "                    break\n",
    "        self.predict()\n",
    "\n",
    "    def make_loaders(self):\n",
    "        num_samples = int(len(self.dataset) / self.config.FOLDS)\n",
    "\n",
    "        intervals = []\n",
    "        for i in range(self.config.FOLDS):\n",
    "            intervals.append((i * num_samples, (i + 1) * num_samples))\n",
    "\n",
    "        if self.val_fold:\n",
    "            val_indices = intervals[self.val_fold - 1]\n",
    "            self.val_ds = Subset(self.dataset, range(*val_indices))\n",
    "            self.val_loader = DataLoader(self.val_ds, batch_size=self.config.BATCH_SIZE, shuffle=True)\n",
    "            intervals.pop(self.val_fold - 1)\n",
    "\n",
    "        self.train_ds = Subset(self.dataset, sum([list(range(*ti)) for ti in intervals], []))\n",
    "        self.train_loader = DataLoader(self.train_ds, batch_size=self.config.BATCH_SIZE, shuffle=True, num_workers=8)\n",
    "        self.test_loader = DataLoader(self.test_ds, batch_size=self.config.BATCH_SIZE, num_workers=8)\n",
    "\n",
    "    def phase(self, train=True):\n",
    "        if train:\n",
    "            self.model.train()\n",
    "            loader = self.train_loader\n",
    "            phase = 'training'\n",
    "        else:\n",
    "            self.model.eval()\n",
    "            loader = self.val_loader\n",
    "            phase = 'validation'\n",
    "        loss_hist = []\n",
    "        pbar = tqdm.tqdm(enumerate(loader), total=len(loader), desc=f'Running {phase} phase...')\n",
    "        for i, batch in pbar:\n",
    "#             print(self.h.heap())\n",
    "            if train:\n",
    "                self.optimizer.zero_grad()\n",
    "            # TODO readability metrics are not guaranteed to be present. Edit code so it won't break without it\n",
    "            input_data = {\n",
    "                i: batch[i].to(self.device) for i in ['ids', 'mask', 'token_type_ids', 'readability_metrics']\n",
    "            }\n",
    "            self.model.eval()\n",
    "#             self.writer.add_graph(self.model, input_data)\n",
    "            outputs = self.model(input_data)\n",
    "            if self.config.WEIGHT_LOSS:\n",
    "                loss = self.criterion(outputs.float(),\n",
    "                                      batch['target'].to(self.device).float(),\n",
    "                                      batch['weight'].to(self.device).float())\n",
    "            else:\n",
    "                loss = self.criterion(outputs.float(), batch['target'].to(self.device).float())\n",
    "            if train:\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "            \n",
    "            loss_hist.append(loss.detach().item() / outputs.shape[0])\n",
    "            avg_loss = np.mean(loss_hist)\n",
    "            pbar.set_postfix({'loss': avg_loss})\n",
    "\n",
    "        if not train:\n",
    "            self.scheduler.step(avg_loss)\n",
    "            if avg_loss < self.best_loss:\n",
    "                self.best_loss = avg_loss\n",
    "                self.best_model = self.model_name\n",
    "                self.save_checkpoint()\n",
    "\n",
    "        # Tensorboard stuff\n",
    "#         self.writer.add_scalar('Loss', np.mean(loss_hist), self.current_epoch)\n",
    "#         for name, param in self.model.named_parameters():\n",
    "#             self.writer.add_histogram(name, param, self.current_epoch)\n",
    "#             if param.grad == None:\n",
    "#                 continue\n",
    "#             self.writer.add_histogram(f'{name}.grad', param.grad, self.current_epoch)\n",
    "\n",
    "    def save_checkpoint(self):\n",
    "        self.model_name = f\"{self.model_timestamp}-epoch-{self.current_epoch}\"\n",
    "        model_path = (self.config.MODEL_SAVE_PATH / self.model_name)\n",
    "        torch.save(self.model.state_dict(), model_path)\n",
    "\n",
    "    def load_checkpoint(self, checkpoint):\n",
    "        self.model.load_state_dict(torch.load(checkpoint))\n",
    "\n",
    "    def predict(self):\n",
    "        predictions = []\n",
    "        self.model.eval()\n",
    "        pbar = tqdm.tqdm(enumerate(self.test_loader), total=len(self.test_loader), desc=f'Running testing phase...')\n",
    "        for i, batch in pbar:\n",
    "            # TODO readability metrics: see line 114\n",
    "            input_data = {\n",
    "                i: batch[i].to(self.device) for i in ['ids', 'mask', 'token_type_ids', 'readability_metrics']\n",
    "            }\n",
    "            outputs = self.model(input_data)\n",
    "            for row in range(len(outputs)):\n",
    "                predictions.append([batch['id'][row], outputs[row].item()])\n",
    "        self.predictions = pd.DataFrame(predictions, columns=('id', 'target'))\n",
    "\n",
    "def loss_fn(output, target, weights=None):\n",
    "    \"\"\"Loss Function\"\"\"\n",
    "    if weights is not None:\n",
    "        # Weights loss function by error\n",
    "        return torch.sqrt((nn.MSELoss(reduction='none')(output.squeeze(), target) * weights).sum() / weights.sum())\n",
    "    else:\n",
    "        return torch.sqrt(nn.MSELoss()(output.squeeze(), target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "agreed-induction",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T19:32:53.487348Z",
     "iopub.status.busy": "2021-05-23T19:32:53.486809Z",
     "iopub.status.idle": "2021-05-23T19:33:06.832939Z",
     "shell.execute_reply": "2021-05-23T19:33:06.832007Z",
     "shell.execute_reply.started": "2021-05-23T18:56:15.367963Z"
    },
    "papermill": {
     "duration": 13.361326,
     "end_time": "2021-05-23T19:33:06.833099",
     "exception": false,
     "start_time": "2021-05-23T19:32:53.471773",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:1621: FutureWarning: Calling BertTokenizer.from_pretrained() with the path to a single file or url is deprecated and won't be possible anymore in v5. Use a model identifier or the path to a directory instead.\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "conf = Config()\n",
    "trainer = Trainer(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "greatest-creature",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T19:33:06.862070Z",
     "iopub.status.busy": "2021-05-23T19:33:06.861328Z",
     "iopub.status.idle": "2021-05-23T20:05:24.417555Z",
     "shell.execute_reply": "2021-05-23T20:05:24.418462Z",
     "shell.execute_reply.started": "2021-05-23T18:56:28.857298Z"
    },
    "papermill": {
     "duration": 1937.573103,
     "end_time": "2021-05-23T20:05:24.418700",
     "exception": false,
     "start_time": "2021-05-23T19:33:06.845597",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training...:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Running training phase...:   0%|          | 0/36 [00:00<?, ?it/s]\u001b[A\n",
      "Running training phase...:   0%|          | 0/36 [01:54<?, ?it/s, loss=0.0376]\u001b[A\n",
      "Running training phase...:   3%|▎         | 1/36 [01:54<1:06:42, 114.37s/it, loss=0.0376]\u001b[A\n",
      "Running training phase...:   3%|▎         | 1/36 [01:55<1:06:42, 114.37s/it, loss=0.0348]\u001b[A\n",
      "Running training phase...:   6%|▌         | 2/36 [01:55<27:04, 47.77s/it, loss=0.0348]   \u001b[A\n",
      "Running training phase...:   6%|▌         | 2/36 [01:56<27:04, 47.77s/it, loss=0.0346]\u001b[A\n",
      "Running training phase...:   8%|▊         | 3/36 [01:56<14:36, 26.55s/it, loss=0.0346]\u001b[A\n",
      "Running training phase...:   8%|▊         | 3/36 [01:57<14:36, 26.55s/it, loss=0.0339]\u001b[A\n",
      "Running training phase...:  11%|█         | 4/36 [01:57<08:48, 16.53s/it, loss=0.0339]\u001b[A\n",
      "Running training phase...:  11%|█         | 4/36 [01:59<08:48, 16.53s/it, loss=0.0333]\u001b[A\n",
      "Running training phase...:  14%|█▍        | 5/36 [01:59<05:40, 10.98s/it, loss=0.0333]\u001b[A\n",
      "Running training phase...:  14%|█▍        | 5/36 [02:00<05:40, 10.98s/it, loss=0.0322]\u001b[A\n",
      "Running training phase...:  17%|█▋        | 6/36 [02:00<03:49,  7.64s/it, loss=0.0322]\u001b[A\n",
      "Running training phase...:  17%|█▋        | 6/36 [02:01<03:49,  7.64s/it, loss=0.0307]\u001b[A\n",
      "Running training phase...:  19%|█▉        | 7/36 [02:01<02:40,  5.52s/it, loss=0.0307]\u001b[A\n",
      "Running training phase...:  19%|█▉        | 7/36 [02:02<02:40,  5.52s/it, loss=0.0297]\u001b[A\n",
      "Running training phase...:  22%|██▏       | 8/36 [02:02<01:55,  4.13s/it, loss=0.0297]\u001b[A\n",
      "Running training phase...:  22%|██▏       | 8/36 [03:46<01:55,  4.13s/it, loss=0.0293]\u001b[A\n",
      "Running training phase...:  25%|██▌       | 9/36 [03:46<15:55, 35.41s/it, loss=0.0293]\u001b[A\n",
      "Running training phase...:  25%|██▌       | 9/36 [03:47<15:55, 35.41s/it, loss=0.0289]\u001b[A\n",
      "Running training phase...:  28%|██▊       | 10/36 [03:47<10:45, 24.83s/it, loss=0.0289]\u001b[A\n",
      "Running training phase...:  28%|██▊       | 10/36 [03:49<10:45, 24.83s/it, loss=0.0278]\u001b[A\n",
      "Running training phase...:  31%|███       | 11/36 [03:49<07:22, 17.69s/it, loss=0.0278]\u001b[A\n",
      "Running training phase...:  31%|███       | 11/36 [03:50<07:22, 17.69s/it, loss=0.0271]\u001b[A\n",
      "Running training phase...:  33%|███▎      | 12/36 [03:50<05:03, 12.66s/it, loss=0.0271]\u001b[A\n",
      "Running training phase...:  33%|███▎      | 12/36 [03:51<05:03, 12.66s/it, loss=0.0264]\u001b[A\n",
      "Running training phase...:  36%|███▌      | 13/36 [03:51<03:30,  9.17s/it, loss=0.0264]\u001b[A\n",
      "Running training phase...:  36%|███▌      | 13/36 [03:52<03:30,  9.17s/it, loss=0.0256]\u001b[A\n",
      "Running training phase...:  39%|███▉      | 14/36 [03:52<02:28,  6.76s/it, loss=0.0256]\u001b[A\n",
      "Running training phase...:  39%|███▉      | 14/36 [03:54<02:28,  6.76s/it, loss=0.025] \u001b[A\n",
      "Running training phase...:  42%|████▏     | 15/36 [03:54<01:46,  5.07s/it, loss=0.025]\u001b[A\n",
      "Running training phase...:  42%|████▏     | 15/36 [03:55<01:46,  5.07s/it, loss=0.0244]\u001b[A\n",
      "Running training phase...:  44%|████▍     | 16/36 [03:55<01:17,  3.88s/it, loss=0.0244]\u001b[A\n",
      "Running training phase...:  44%|████▍     | 16/36 [05:39<01:17,  3.88s/it, loss=0.0239]\u001b[A\n",
      "Running training phase...:  47%|████▋     | 17/36 [05:39<10:48, 34.12s/it, loss=0.0239]\u001b[A\n",
      "Running training phase...:  47%|████▋     | 17/36 [05:40<10:48, 34.12s/it, loss=0.0235]\u001b[A\n",
      "Running training phase...:  50%|█████     | 18/36 [05:40<07:15, 24.21s/it, loss=0.0235]\u001b[A\n",
      "Running training phase...:  50%|█████     | 18/36 [05:41<07:15, 24.21s/it, loss=0.0232]\u001b[A\n",
      "Running training phase...:  53%|█████▎    | 19/36 [05:41<04:54, 17.29s/it, loss=0.0232]\u001b[A\n",
      "Running training phase...:  53%|█████▎    | 19/36 [05:43<04:54, 17.29s/it, loss=0.0229]\u001b[A\n",
      "Running training phase...:  56%|█████▌    | 20/36 [05:43<03:19, 12.45s/it, loss=0.0229]\u001b[A\n",
      "Running training phase...:  56%|█████▌    | 20/36 [05:44<03:19, 12.45s/it, loss=0.0226]\u001b[A\n",
      "Running training phase...:  58%|█████▊    | 21/36 [05:44<02:15,  9.06s/it, loss=0.0226]\u001b[A\n",
      "Running training phase...:  58%|█████▊    | 21/36 [05:45<02:15,  9.06s/it, loss=0.0223]\u001b[A\n",
      "Running training phase...:  61%|██████    | 22/36 [05:45<01:33,  6.69s/it, loss=0.0223]\u001b[A\n",
      "Running training phase...:  61%|██████    | 22/36 [05:46<01:33,  6.69s/it, loss=0.022] \u001b[A\n",
      "Running training phase...:  64%|██████▍   | 23/36 [05:46<01:05,  5.02s/it, loss=0.022]\u001b[A\n",
      "Running training phase...:  64%|██████▍   | 23/36 [05:47<01:05,  5.02s/it, loss=0.0217]\u001b[A\n",
      "Running training phase...:  67%|██████▋   | 24/36 [05:47<00:46,  3.86s/it, loss=0.0217]\u001b[A\n",
      "Running training phase...:  67%|██████▋   | 24/36 [07:30<00:46,  3.86s/it, loss=0.0215]\u001b[A\n",
      "Running training phase...:  69%|██████▉   | 25/36 [07:30<06:09, 33.57s/it, loss=0.0215]\u001b[A\n",
      "Running training phase...:  69%|██████▉   | 25/36 [07:31<06:09, 33.57s/it, loss=0.0214]\u001b[A\n",
      "Running training phase...:  72%|███████▏  | 26/36 [07:31<03:58, 23.84s/it, loss=0.0214]\u001b[A\n",
      "Running training phase...:  72%|███████▏  | 26/36 [07:34<03:58, 23.84s/it, loss=0.0212]\u001b[A\n",
      "Running training phase...:  75%|███████▌  | 27/36 [07:34<02:36, 17.39s/it, loss=0.0212]\u001b[A\n",
      "Running training phase...:  75%|███████▌  | 27/36 [07:35<02:36, 17.39s/it, loss=0.0211]\u001b[A\n",
      "Running training phase...:  78%|███████▊  | 28/36 [07:35<01:40, 12.51s/it, loss=0.0211]\u001b[A\n",
      "Running training phase...:  78%|███████▊  | 28/36 [07:36<01:40, 12.51s/it, loss=0.021] \u001b[A\n",
      "Running training phase...:  81%|████████  | 29/36 [07:36<01:03,  9.10s/it, loss=0.021]\u001b[A\n",
      "Running training phase...:  81%|████████  | 29/36 [07:37<01:03,  9.10s/it, loss=0.0208]\u001b[A\n",
      "Running training phase...:  83%|████████▎ | 30/36 [07:37<00:40,  6.71s/it, loss=0.0208]\u001b[A\n",
      "Running training phase...:  83%|████████▎ | 30/36 [07:38<00:40,  6.71s/it, loss=0.0207]\u001b[A\n",
      "Running training phase...:  86%|████████▌ | 31/36 [07:38<00:25,  5.03s/it, loss=0.0207]\u001b[A\n",
      "Running training phase...:  86%|████████▌ | 31/36 [07:39<00:25,  5.03s/it, loss=0.0205]\u001b[A\n",
      "Running training phase...:  89%|████████▉ | 32/36 [07:39<00:15,  3.86s/it, loss=0.0205]\u001b[A\n",
      "Running training phase...:  89%|████████▉ | 32/36 [08:18<00:15,  3.86s/it, loss=0.0204]\u001b[A\n",
      "Running training phase...:  92%|█████████▏| 33/36 [08:18<00:42, 14.22s/it, loss=0.0204]\u001b[A\n",
      "Running training phase...:  92%|█████████▏| 33/36 [08:19<00:42, 14.22s/it, loss=0.0202]\u001b[A\n",
      "Running training phase...:  94%|█████████▍| 34/36 [08:19<00:20, 10.29s/it, loss=0.0202]\u001b[A\n",
      "Running training phase...:  94%|█████████▍| 34/36 [08:21<00:20, 10.29s/it, loss=0.0201]\u001b[A\n",
      "Running training phase...:  97%|█████████▋| 35/36 [08:21<00:07,  7.74s/it, loss=0.0201]\u001b[A\n",
      "Running training phase...:  97%|█████████▋| 35/36 [08:21<00:07,  7.74s/it, loss=0.0207]\u001b[A\n",
      "Running training phase...: 100%|██████████| 36/36 [08:21<00:00, 13.93s/it, loss=0.0207]\n",
      "\n",
      "Running validation phase...:   0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Running validation phase...:   0%|          | 0/9 [00:17<?, ?it/s, loss=0.012]\u001b[A\n",
      "Running validation phase...:  11%|█         | 1/9 [00:17<02:17, 17.23s/it, loss=0.012]\u001b[A\n",
      "Running validation phase...:  11%|█         | 1/9 [00:34<02:17, 17.23s/it, loss=0.013]\u001b[A\n",
      "Running validation phase...:  22%|██▏       | 2/9 [00:34<01:59, 17.02s/it, loss=0.013]\u001b[A\n",
      "Running validation phase...:  22%|██▏       | 2/9 [00:50<01:59, 17.02s/it, loss=0.0143]\u001b[A\n",
      "Running validation phase...:  33%|███▎      | 3/9 [00:50<01:40, 16.79s/it, loss=0.0143]\u001b[A\n",
      "Running validation phase...:  33%|███▎      | 3/9 [01:06<01:40, 16.79s/it, loss=0.0141]\u001b[A\n",
      "Running validation phase...:  44%|████▍     | 4/9 [01:06<01:22, 16.60s/it, loss=0.0141]\u001b[A\n",
      "Running validation phase...:  44%|████▍     | 4/9 [01:23<01:22, 16.60s/it, loss=0.0141]\u001b[A\n",
      "Running validation phase...:  56%|█████▌    | 5/9 [01:23<01:07, 16.76s/it, loss=0.0141]\u001b[A\n",
      "Running validation phase...:  56%|█████▌    | 5/9 [01:40<01:07, 16.76s/it, loss=0.0137]\u001b[A\n",
      "Running validation phase...:  67%|██████▋   | 6/9 [01:40<00:49, 16.66s/it, loss=0.0137]\u001b[A\n",
      "Running validation phase...:  67%|██████▋   | 6/9 [01:57<00:49, 16.66s/it, loss=0.014] \u001b[A\n",
      "Running validation phase...:  78%|███████▊  | 7/9 [01:57<00:33, 16.85s/it, loss=0.014]\u001b[A\n",
      "Running validation phase...:  78%|███████▊  | 7/9 [02:13<00:33, 16.85s/it, loss=0.0139]\u001b[A\n",
      "Running validation phase...:  89%|████████▉ | 8/9 [02:13<00:16, 16.58s/it, loss=0.0139]\u001b[A\n",
      "Running validation phase...:  89%|████████▉ | 8/9 [02:28<00:16, 16.58s/it, loss=0.0139]\u001b[A\n",
      "Running validation phase...: 100%|██████████| 9/9 [02:28<00:00, 16.48s/it, loss=0.0139]\n",
      "Running training...:  33%|███▎      | 1/3 [10:51<21:42, 651.18s/it]\n",
      "Running training phase...:   0%|          | 0/36 [00:00<?, ?it/s]\u001b[A\n",
      "Running training phase...:   0%|          | 0/36 [01:57<?, ?it/s, loss=0.0146]\u001b[A\n",
      "Running training phase...:   3%|▎         | 1/36 [01:57<1:08:16, 117.05s/it, loss=0.0146]\u001b[A\n",
      "Running training phase...:   3%|▎         | 1/36 [01:58<1:08:16, 117.05s/it, loss=0.0149]\u001b[A\n",
      "Running training phase...:   6%|▌         | 2/36 [01:58<27:41, 48.88s/it, loss=0.0149]   \u001b[A\n",
      "Running training phase...:   6%|▌         | 2/36 [01:59<27:41, 48.88s/it, loss=0.0149]\u001b[A\n",
      "Running training phase...:   8%|▊         | 3/36 [01:59<14:53, 27.09s/it, loss=0.0149]\u001b[A\n",
      "Running training phase...:   8%|▊         | 3/36 [02:00<14:53, 27.09s/it, loss=0.015] \u001b[A\n",
      "Running training phase...:  11%|█         | 4/36 [02:00<08:59, 16.85s/it, loss=0.015]\u001b[A\n",
      "Running training phase...:  11%|█         | 4/36 [02:01<08:59, 16.85s/it, loss=0.0148]\u001b[A\n",
      "Running training phase...:  14%|█▍        | 5/36 [02:01<05:47, 11.19s/it, loss=0.0148]\u001b[A\n",
      "Running training phase...:  14%|█▍        | 5/36 [02:02<05:47, 11.19s/it, loss=0.0147]\u001b[A\n",
      "Running training phase...:  17%|█▋        | 6/36 [02:02<03:53,  7.78s/it, loss=0.0147]\u001b[A\n",
      "Running training phase...:  17%|█▋        | 6/36 [02:03<03:53,  7.78s/it, loss=0.015] \u001b[A\n",
      "Running training phase...:  19%|█▉        | 7/36 [02:04<02:42,  5.62s/it, loss=0.015]\u001b[A\n",
      "Running training phase...:  19%|█▉        | 7/36 [02:05<02:42,  5.62s/it, loss=0.0149]\u001b[A\n",
      "Running training phase...:  22%|██▏       | 8/36 [02:05<01:57,  4.20s/it, loss=0.0149]\u001b[A\n",
      "Running training phase...:  22%|██▏       | 8/36 [03:49<01:57,  4.20s/it, loss=0.015] \u001b[A\n",
      "Running training phase...:  25%|██▌       | 9/36 [03:49<15:59, 35.53s/it, loss=0.015]\u001b[A\n",
      "Running training phase...:  25%|██▌       | 9/36 [03:50<15:59, 35.53s/it, loss=0.015]\u001b[A\n",
      "Running training phase...:  28%|██▊       | 10/36 [03:50<10:47, 24.91s/it, loss=0.015]\u001b[A\n",
      "Running training phase...:  28%|██▊       | 10/36 [03:51<10:47, 24.91s/it, loss=0.0151]\u001b[A\n",
      "Running training phase...:  31%|███       | 11/36 [03:51<07:20, 17.64s/it, loss=0.0151]\u001b[A\n",
      "Running training phase...:  31%|███       | 11/36 [03:53<07:20, 17.64s/it, loss=0.0153]\u001b[A\n",
      "Running training phase...:  33%|███▎      | 12/36 [03:53<05:03, 12.63s/it, loss=0.0153]\u001b[A\n",
      "Running training phase...:  33%|███▎      | 12/36 [03:54<05:03, 12.63s/it, loss=0.0153]\u001b[A\n",
      "Running training phase...:  36%|███▌      | 13/36 [03:54<03:30,  9.15s/it, loss=0.0153]\u001b[A\n",
      "Running training phase...:  36%|███▌      | 13/36 [03:55<03:30,  9.15s/it, loss=0.0153]\u001b[A\n",
      "Running training phase...:  39%|███▉      | 14/36 [03:55<02:28,  6.74s/it, loss=0.0153]\u001b[A\n",
      "Running training phase...:  39%|███▉      | 14/36 [03:56<02:28,  6.74s/it, loss=0.0153]\u001b[A\n",
      "Running training phase...:  42%|████▏     | 15/36 [03:56<01:46,  5.05s/it, loss=0.0153]\u001b[A\n",
      "Running training phase...:  42%|████▏     | 15/36 [03:57<01:46,  5.05s/it, loss=0.0152]\u001b[A\n",
      "Running training phase...:  44%|████▍     | 16/36 [03:57<01:17,  3.87s/it, loss=0.0152]\u001b[A\n",
      "Running training phase...:  44%|████▍     | 16/36 [05:39<01:17,  3.87s/it, loss=0.0153]\u001b[A\n",
      "Running training phase...:  47%|████▋     | 17/36 [05:39<10:35, 33.43s/it, loss=0.0153]\u001b[A\n",
      "Running training phase...:  47%|████▋     | 17/36 [05:40<10:35, 33.43s/it, loss=0.0153]\u001b[A\n",
      "Running training phase...:  50%|█████     | 18/36 [05:40<07:07, 23.74s/it, loss=0.0153]\u001b[A\n",
      "Running training phase...:  50%|█████     | 18/36 [05:42<07:07, 23.74s/it, loss=0.0154]\u001b[A\n",
      "Running training phase...:  53%|█████▎    | 19/36 [05:42<04:48, 16.96s/it, loss=0.0154]\u001b[A\n",
      "Running training phase...:  53%|█████▎    | 19/36 [05:43<04:48, 16.96s/it, loss=0.0154]\u001b[A\n",
      "Running training phase...:  56%|█████▌    | 20/36 [05:43<03:15, 12.21s/it, loss=0.0154]\u001b[A\n",
      "Running training phase...:  56%|█████▌    | 20/36 [05:44<03:15, 12.21s/it, loss=0.0153]\u001b[A\n",
      "Running training phase...:  58%|█████▊    | 21/36 [05:44<02:13,  8.89s/it, loss=0.0153]\u001b[A\n",
      "Running training phase...:  58%|█████▊    | 21/36 [05:45<02:13,  8.89s/it, loss=0.0152]\u001b[A\n",
      "Running training phase...:  61%|██████    | 22/36 [05:45<01:31,  6.57s/it, loss=0.0152]\u001b[A\n",
      "Running training phase...:  61%|██████    | 22/36 [05:46<01:31,  6.57s/it, loss=0.0152]\u001b[A\n",
      "Running training phase...:  64%|██████▍   | 23/36 [05:46<01:04,  4.94s/it, loss=0.0152]\u001b[A\n",
      "Running training phase...:  64%|██████▍   | 23/36 [05:47<01:04,  4.94s/it, loss=0.0151]\u001b[A\n",
      "Running training phase...:  67%|██████▋   | 24/36 [05:47<00:45,  3.80s/it, loss=0.0151]\u001b[A\n",
      "Running training phase...:  67%|██████▋   | 24/36 [07:28<00:45,  3.80s/it, loss=0.0151]\u001b[A\n",
      "Running training phase...:  69%|██████▉   | 25/36 [07:28<06:01, 32.84s/it, loss=0.0151]\u001b[A\n",
      "Running training phase...:  69%|██████▉   | 25/36 [07:29<06:01, 32.84s/it, loss=0.0151]\u001b[A\n",
      "Running training phase...:  72%|███████▏  | 26/36 [07:29<03:53, 23.33s/it, loss=0.0151]\u001b[A\n",
      "Running training phase...:  72%|███████▏  | 26/36 [07:30<03:53, 23.33s/it, loss=0.0151]\u001b[A\n",
      "Running training phase...:  75%|███████▌  | 27/36 [07:30<02:30, 16.67s/it, loss=0.0151]\u001b[A\n",
      "Running training phase...:  75%|███████▌  | 27/36 [07:31<02:30, 16.67s/it, loss=0.0151]\u001b[A\n",
      "Running training phase...:  78%|███████▊  | 28/36 [07:31<01:36, 12.01s/it, loss=0.0151]\u001b[A\n",
      "Running training phase...:  78%|███████▊  | 28/36 [07:32<01:36, 12.01s/it, loss=0.0151]\u001b[A\n",
      "Running training phase...:  81%|████████  | 29/36 [07:33<01:01,  8.74s/it, loss=0.0151]\u001b[A\n",
      "Running training phase...:  81%|████████  | 29/36 [07:34<01:01,  8.74s/it, loss=0.0151]\u001b[A\n",
      "Running training phase...:  83%|████████▎ | 30/36 [07:34<00:38,  6.46s/it, loss=0.0151]\u001b[A\n",
      "Running training phase...:  83%|████████▎ | 30/36 [07:35<00:38,  6.46s/it, loss=0.0151]\u001b[A\n",
      "Running training phase...:  86%|████████▌ | 31/36 [07:35<00:24,  4.86s/it, loss=0.0151]\u001b[A\n",
      "Running training phase...:  86%|████████▌ | 31/36 [07:36<00:24,  4.86s/it, loss=0.0151]\u001b[A\n",
      "Running training phase...:  89%|████████▉ | 32/36 [07:36<00:14,  3.74s/it, loss=0.0151]\u001b[A\n",
      "Running training phase...:  89%|████████▉ | 32/36 [08:15<00:14,  3.74s/it, loss=0.0151]\u001b[A\n",
      "Running training phase...:  92%|█████████▏| 33/36 [08:15<00:43, 14.45s/it, loss=0.0151]\u001b[A\n",
      "Running training phase...:  92%|█████████▏| 33/36 [08:16<00:43, 14.45s/it, loss=0.0151]\u001b[A\n",
      "Running training phase...:  94%|█████████▍| 34/36 [08:16<00:20, 10.45s/it, loss=0.0151]\u001b[A\n",
      "Running training phase...:  94%|█████████▍| 34/36 [08:18<00:20, 10.45s/it, loss=0.0151]\u001b[A\n",
      "Running training phase...:  97%|█████████▋| 35/36 [08:18<00:07,  7.64s/it, loss=0.0151]\u001b[A\n",
      "Running training phase...:  97%|█████████▋| 35/36 [08:18<00:07,  7.64s/it, loss=0.0158]\u001b[A\n",
      "Running training phase...: 100%|██████████| 36/36 [08:18<00:00, 13.85s/it, loss=0.0158]\n",
      "\n",
      "Running validation phase...:   0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Running validation phase...:   0%|          | 0/9 [00:13<?, ?it/s, loss=0.0127]\u001b[A\n",
      "Running validation phase...:  11%|█         | 1/9 [00:13<01:45, 13.19s/it, loss=0.0127]\u001b[A\n",
      "Running validation phase...:  11%|█         | 1/9 [00:28<01:45, 13.19s/it, loss=0.0126]\u001b[A\n",
      "Running validation phase...:  22%|██▏       | 2/9 [00:28<01:43, 14.72s/it, loss=0.0126]\u001b[A\n",
      "Running validation phase...:  22%|██▏       | 2/9 [00:45<01:43, 14.72s/it, loss=0.0137]\u001b[A\n",
      "Running validation phase...:  33%|███▎      | 3/9 [00:45<01:31, 15.33s/it, loss=0.0137]\u001b[A\n",
      "Running validation phase...:  33%|███▎      | 3/9 [01:01<01:31, 15.33s/it, loss=0.0134]\u001b[A\n",
      "Running validation phase...:  44%|████▍     | 4/9 [01:01<01:19, 15.82s/it, loss=0.0134]\u001b[A\n",
      "Running validation phase...:  44%|████▍     | 4/9 [01:17<01:19, 15.82s/it, loss=0.0135]\u001b[A\n",
      "Running validation phase...:  56%|█████▌    | 5/9 [01:17<01:03, 15.91s/it, loss=0.0135]\u001b[A\n",
      "Running validation phase...:  56%|█████▌    | 5/9 [01:34<01:03, 15.91s/it, loss=0.0131]\u001b[A\n",
      "Running validation phase...:  67%|██████▋   | 6/9 [01:34<00:48, 16.29s/it, loss=0.0131]\u001b[A\n",
      "Running validation phase...:  67%|██████▋   | 6/9 [01:50<00:48, 16.29s/it, loss=0.0131]\u001b[A\n",
      "Running validation phase...:  78%|███████▊  | 7/9 [01:50<00:32, 16.15s/it, loss=0.0131]\u001b[A\n",
      "Running validation phase...:  78%|███████▊  | 7/9 [02:06<00:32, 16.15s/it, loss=0.0131]\u001b[A\n",
      "Running validation phase...:  89%|████████▉ | 8/9 [02:06<00:16, 16.17s/it, loss=0.0131]\u001b[A\n",
      "Running validation phase...:  89%|████████▉ | 8/9 [02:20<00:16, 16.17s/it, loss=0.0132]\u001b[A\n",
      "Running validation phase...: 100%|██████████| 9/9 [02:20<00:00, 15.62s/it, loss=0.0132]\n",
      "Running training...:  67%|██████▋   | 2/3 [21:31<10:44, 644.75s/it]\n",
      "Running training phase...:   0%|          | 0/36 [00:00<?, ?it/s]\u001b[A\n",
      "Running training phase...:   0%|          | 0/36 [01:51<?, ?it/s, loss=0.0139]\u001b[A\n",
      "Running training phase...:   3%|▎         | 1/36 [01:51<1:05:19, 112.00s/it, loss=0.0139]\u001b[A\n",
      "Running training phase...:   3%|▎         | 1/36 [01:53<1:05:19, 112.00s/it, loss=0.0137]\u001b[A\n",
      "Running training phase...:   6%|▌         | 2/36 [01:53<26:34, 46.89s/it, loss=0.0137]   \u001b[A\n",
      "Running training phase...:   6%|▌         | 2/36 [01:55<26:34, 46.89s/it, loss=0.014] \u001b[A\n",
      "Running training phase...:   8%|▊         | 3/36 [01:55<14:39, 26.66s/it, loss=0.014]\u001b[A\n",
      "Running training phase...:   8%|▊         | 3/36 [01:57<14:39, 26.66s/it, loss=0.014]\u001b[A\n",
      "Running training phase...:  11%|█         | 4/36 [01:57<08:50, 16.59s/it, loss=0.014]\u001b[A\n",
      "Running training phase...:  11%|█         | 4/36 [01:58<08:50, 16.59s/it, loss=0.0139]\u001b[A\n",
      "Running training phase...:  14%|█▍        | 5/36 [01:58<05:41, 11.03s/it, loss=0.0139]\u001b[A\n",
      "Running training phase...:  14%|█▍        | 5/36 [01:59<05:41, 11.03s/it, loss=0.0142]\u001b[A\n",
      "Running training phase...:  17%|█▋        | 6/36 [01:59<03:50,  7.67s/it, loss=0.0142]\u001b[A\n",
      "Running training phase...:  17%|█▋        | 6/36 [02:00<03:50,  7.67s/it, loss=0.0142]\u001b[A\n",
      "Running training phase...:  19%|█▉        | 7/36 [02:00<02:40,  5.54s/it, loss=0.0142]\u001b[A\n",
      "Running training phase...:  19%|█▉        | 7/36 [02:01<02:40,  5.54s/it, loss=0.0143]\u001b[A\n",
      "Running training phase...:  22%|██▏       | 8/36 [02:01<01:55,  4.14s/it, loss=0.0143]\u001b[A\n",
      "Running training phase...:  22%|██▏       | 8/36 [03:44<01:55,  4.14s/it, loss=0.0142]\u001b[A\n",
      "Running training phase...:  25%|██▌       | 9/36 [03:44<15:44, 35.00s/it, loss=0.0142]\u001b[A\n",
      "Running training phase...:  25%|██▌       | 9/36 [03:45<15:44, 35.00s/it, loss=0.0141]\u001b[A\n",
      "Running training phase...:  28%|██▊       | 10/36 [03:45<10:38, 24.55s/it, loss=0.0141]\u001b[A\n",
      "Running training phase...:  28%|██▊       | 10/36 [03:47<10:38, 24.55s/it, loss=0.0141]\u001b[A\n",
      "Running training phase...:  31%|███       | 11/36 [03:47<07:18, 17.54s/it, loss=0.0141]\u001b[A\n",
      "Running training phase...:  31%|███       | 11/36 [03:50<07:18, 17.54s/it, loss=0.0141]\u001b[A\n",
      "Running training phase...:  33%|███▎      | 12/36 [03:50<05:16, 13.20s/it, loss=0.0141]\u001b[A\n",
      "Running training phase...:  33%|███▎      | 12/36 [03:51<05:16, 13.20s/it, loss=0.0142]\u001b[A\n",
      "Running training phase...:  36%|███▌      | 13/36 [03:51<03:39,  9.55s/it, loss=0.0142]\u001b[A\n",
      "Running training phase...:  36%|███▌      | 13/36 [03:52<03:39,  9.55s/it, loss=0.0141]\u001b[A\n",
      "Running training phase...:  39%|███▉      | 14/36 [03:52<02:34,  7.01s/it, loss=0.0141]\u001b[A\n",
      "Running training phase...:  39%|███▉      | 14/36 [03:54<02:34,  7.01s/it, loss=0.0141]\u001b[A\n",
      "Running training phase...:  42%|████▏     | 15/36 [03:54<01:50,  5.25s/it, loss=0.0141]\u001b[A\n",
      "Running training phase...:  42%|████▏     | 15/36 [03:55<01:50,  5.25s/it, loss=0.0142]\u001b[A\n",
      "Running training phase...:  44%|████▍     | 16/36 [03:55<01:20,  4.01s/it, loss=0.0142]\u001b[A\n",
      "Running training phase...:  44%|████▍     | 16/36 [05:40<01:20,  4.01s/it, loss=0.0142]\u001b[A\n",
      "Running training phase...:  47%|████▋     | 17/36 [05:40<10:54, 34.44s/it, loss=0.0142]\u001b[A\n",
      "Running training phase...:  47%|████▋     | 17/36 [05:41<10:54, 34.44s/it, loss=0.0142]\u001b[A\n",
      "Running training phase...:  50%|█████     | 18/36 [05:41<07:20, 24.45s/it, loss=0.0142]\u001b[A\n",
      "Running training phase...:  50%|█████     | 18/36 [05:42<07:20, 24.45s/it, loss=0.014] \u001b[A\n",
      "Running training phase...:  53%|█████▎    | 19/36 [05:42<04:56, 17.46s/it, loss=0.014]\u001b[A\n",
      "Running training phase...:  53%|█████▎    | 19/36 [05:43<04:56, 17.46s/it, loss=0.014]\u001b[A\n",
      "Running training phase...:  56%|█████▌    | 20/36 [05:43<03:21, 12.57s/it, loss=0.014]\u001b[A\n",
      "Running training phase...:  56%|█████▌    | 20/36 [05:45<03:21, 12.57s/it, loss=0.014]\u001b[A\n",
      "Running training phase...:  58%|█████▊    | 21/36 [05:45<02:17,  9.14s/it, loss=0.014]\u001b[A\n",
      "Running training phase...:  58%|█████▊    | 21/36 [05:46<02:17,  9.14s/it, loss=0.0138]\u001b[A\n",
      "Running training phase...:  61%|██████    | 22/36 [05:46<01:34,  6.74s/it, loss=0.0138]\u001b[A\n",
      "Running training phase...:  61%|██████    | 22/36 [05:47<01:34,  6.74s/it, loss=0.0138]\u001b[A\n",
      "Running training phase...:  64%|██████▍   | 23/36 [05:47<01:05,  5.06s/it, loss=0.0138]\u001b[A\n",
      "Running training phase...:  64%|██████▍   | 23/36 [05:48<01:05,  5.06s/it, loss=0.0138]\u001b[A\n",
      "Running training phase...:  67%|██████▋   | 24/36 [05:48<00:46,  3.89s/it, loss=0.0138]\u001b[A\n",
      "Running training phase...:  67%|██████▋   | 24/36 [07:30<00:46,  3.89s/it, loss=0.0137]\u001b[A\n",
      "Running training phase...:  69%|██████▉   | 25/36 [07:30<06:07, 33.40s/it, loss=0.0137]\u001b[A\n",
      "Running training phase...:  69%|██████▉   | 25/36 [07:31<06:07, 33.40s/it, loss=0.0138]\u001b[A\n",
      "Running training phase...:  72%|███████▏  | 26/36 [07:31<03:57, 23.72s/it, loss=0.0138]\u001b[A\n",
      "Running training phase...:  72%|███████▏  | 26/36 [07:33<03:57, 23.72s/it, loss=0.0138]\u001b[A\n",
      "Running training phase...:  75%|███████▌  | 27/36 [07:33<02:32, 16.95s/it, loss=0.0138]\u001b[A\n",
      "Running training phase...:  75%|███████▌  | 27/36 [07:34<02:32, 16.95s/it, loss=0.0138]\u001b[A\n",
      "Running training phase...:  78%|███████▊  | 28/36 [07:34<01:37, 12.20s/it, loss=0.0138]\u001b[A\n",
      "Running training phase...:  78%|███████▊  | 28/36 [07:35<01:37, 12.20s/it, loss=0.0138]\u001b[A\n",
      "Running training phase...:  81%|████████  | 29/36 [07:35<01:02,  8.88s/it, loss=0.0138]\u001b[A\n",
      "Running training phase...:  81%|████████  | 29/36 [07:36<01:02,  8.88s/it, loss=0.0137]\u001b[A\n",
      "Running training phase...:  83%|████████▎ | 30/36 [07:36<00:39,  6.56s/it, loss=0.0137]\u001b[A\n",
      "Running training phase...:  83%|████████▎ | 30/36 [07:37<00:39,  6.56s/it, loss=0.0137]\u001b[A\n",
      "Running training phase...:  86%|████████▌ | 31/36 [07:37<00:24,  4.93s/it, loss=0.0137]\u001b[A\n",
      "Running training phase...:  86%|████████▌ | 31/36 [07:38<00:24,  4.93s/it, loss=0.0137]\u001b[A\n",
      "Running training phase...:  89%|████████▉ | 32/36 [07:38<00:15,  3.79s/it, loss=0.0137]\u001b[A\n",
      "Running training phase...:  89%|████████▉ | 32/36 [08:17<00:15,  3.79s/it, loss=0.0138]\u001b[A\n",
      "Running training phase...:  92%|█████████▏| 33/36 [08:17<00:43, 14.36s/it, loss=0.0138]\u001b[A\n",
      "Running training phase...:  92%|█████████▏| 33/36 [08:18<00:43, 14.36s/it, loss=0.0138]\u001b[A\n",
      "Running training phase...:  94%|█████████▍| 34/36 [08:18<00:20, 10.38s/it, loss=0.0138]\u001b[A\n",
      "Running training phase...:  94%|█████████▍| 34/36 [08:19<00:20, 10.38s/it, loss=0.0137]\u001b[A\n",
      "Running training phase...:  97%|█████████▋| 35/36 [08:19<00:07,  7.60s/it, loss=0.0137]\u001b[A\n",
      "Running training phase...:  97%|█████████▋| 35/36 [08:20<00:07,  7.60s/it, loss=0.0142]\u001b[A\n",
      "Running training phase...: 100%|██████████| 36/36 [08:20<00:00, 13.90s/it, loss=0.0142]\n",
      "\n",
      "Running validation phase...:   0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Running validation phase...:   0%|          | 0/9 [00:14<?, ?it/s, loss=0.0121]\u001b[A\n",
      "Running validation phase...:  11%|█         | 1/9 [00:14<01:53, 14.15s/it, loss=0.0121]\u001b[A\n",
      "Running validation phase...:  11%|█         | 1/9 [00:29<01:53, 14.15s/it, loss=0.0122]\u001b[A\n",
      "Running validation phase...:  22%|██▏       | 2/9 [00:29<01:44, 14.88s/it, loss=0.0122]\u001b[A\n",
      "Running validation phase...:  22%|██▏       | 2/9 [00:46<01:44, 14.88s/it, loss=0.0118]\u001b[A\n",
      "Running validation phase...:  33%|███▎      | 3/9 [00:46<01:33, 15.62s/it, loss=0.0118]\u001b[A\n",
      "Running validation phase...:  33%|███▎      | 3/9 [01:02<01:33, 15.62s/it, loss=0.0125]\u001b[A\n",
      "Running validation phase...:  44%|████▍     | 4/9 [01:02<01:19, 15.87s/it, loss=0.0125]\u001b[A\n",
      "Running validation phase...:  44%|████▍     | 4/9 [01:18<01:19, 15.87s/it, loss=0.0128]\u001b[A\n",
      "Running validation phase...:  56%|█████▌    | 5/9 [01:18<01:04, 16.10s/it, loss=0.0128]\u001b[A\n",
      "Running validation phase...:  56%|█████▌    | 5/9 [01:35<01:04, 16.10s/it, loss=0.0127]\u001b[A\n",
      "Running validation phase...:  67%|██████▋   | 6/9 [01:35<00:48, 16.29s/it, loss=0.0127]\u001b[A\n",
      "Running validation phase...:  67%|██████▋   | 6/9 [01:52<00:48, 16.29s/it, loss=0.0125]\u001b[A\n",
      "Running validation phase...:  78%|███████▊  | 7/9 [01:52<00:32, 16.38s/it, loss=0.0125]\u001b[A\n",
      "Running validation phase...:  78%|███████▊  | 7/9 [02:08<00:32, 16.38s/it, loss=0.0125]\u001b[A\n",
      "Running validation phase...:  89%|████████▉ | 8/9 [02:08<00:16, 16.30s/it, loss=0.0125]\u001b[A\n",
      "Running validation phase...:  89%|████████▉ | 8/9 [02:22<00:16, 16.30s/it, loss=0.0127]\u001b[A\n",
      "Running validation phase...: 100%|██████████| 9/9 [02:22<00:00, 15.81s/it, loss=0.0127]\n",
      "Running training...: 100%|██████████| 3/3 [32:15<00:00, 645.09s/it]\n",
      "Running testing phase...: 100%|██████████| 1/1 [00:01<00:00,  1.91s/it]\n"
     ]
    }
   ],
   "source": [
    "trainer.run()\n",
    "trainer.predictions.to_csv('./submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valid-truth",
   "metadata": {
    "papermill": {
     "duration": 0.219307,
     "end_time": "2021-05-23T20:05:24.906982",
     "exception": false,
     "start_time": "2021-05-23T20:05:24.687675",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dominican-attraction",
   "metadata": {
    "papermill": {
     "duration": 0.269624,
     "end_time": "2021-05-23T20:05:25.398739",
     "exception": false,
     "start_time": "2021-05-23T20:05:25.129115",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2014.320898,
   "end_time": "2021-05-23T20:05:27.071519",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-05-23T19:31:52.750621",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
